{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a54cc36",
   "metadata": {},
   "source": [
    "# XAI - 2025 - TP1 - Feature Selection\n",
    "\n",
    "\n",
    "But du TP: \n",
    "\n",
    "- Explorer plus en profondeur la sélection d'attributs (Feature Selection) dans une optique d'interprétabilité. Répondez aux questions et complétez le code directement dans le notebook et n'oubliez pas de changer le nom du fichier avec votre nom et prénom. \n",
    "\n",
    "Rendu du TP: \n",
    "\n",
    "- Durée 2 semaines\n",
    "- Mercredi 12 mars 2025 23h59, Cyberlearn\n",
    "\n",
    "Description: \n",
    "\n",
    "   - Le dataset [MILE](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE13159) contient pour ~2000 patients les données d'expression d'environ 54'000 gènes. Afin d'accélérer le début de ce TP, les features ont déjà été écrémées grâce à trois méthodes différentes (chi2, mutual_information et f_score) qui ont chacunes retourné les 5000 meilleures variables (features). \n",
    "\n",
    "Dans ce travail vous devrez: \n",
    "\n",
    "1. Comparer les features sélectionnées par les premières méthodes de filtre et en retourner un subset adéquat.\n",
    "\n",
    "     \n",
    "2. Appliquer méthodes wrapper sur le dataset choisi\n",
    "\n",
    "    a. RFE-RF\n",
    "    \n",
    "    b. RFE-SVM\n",
    "\n",
    "\n",
    "3. Entrainer un modèle et en extraire les features les plus importantes\n",
    "\n",
    "    a. Random Forest (RF)\n",
    "    \n",
    "    b. Support Vector Machine (SVM)\n",
    "    \n",
    "    \n",
    "4. Sélectionner les attributs les plus pertinents\n",
    "\n",
    "    a. Entrainer des modèles (RF et SVM) avec le dataset réduit \n",
    "\n",
    "\n",
    "5. Essayez une méthode d'ensemble pour la feature selection\n",
    "\n",
    "\n",
    "6. Analyse des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71be488",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1) Filter methods\n",
    "\n",
    "Trois méthodes de *features selection* ont été préalablement appliquées au dataset original afin de vous éviter un temps de calcul trop long. De ce dataset, qui contient 54'000 attributs (ou features, ou variables), chaque méthode en a retenu 5000 qui sont présents dans les trois fichiers csv joints et qui sont lus ci-dessous. \n",
    "\n",
    "- Explorez rapidement les données\n",
    "- Exécutez et comprenez le code ci-dessous et répondez aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si nécessaire installez les packages suivants:\n",
    "\n",
    "#!conda install scikit-learn\n",
    "#!pip install matplotlib_venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade --force-reinstall numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03554d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the three datasets with each 5000 variables previously selected with the \n",
    "# sklearn.SelectKBest method with the following scoring functions (filters)\n",
    "\n",
    "# - mutual_information_score\n",
    "# - chi2\n",
    "# - f_classifier\n",
    "\n",
    "# Note: leukemia_class will be considered a feature and replaced at the end !\n",
    "\n",
    "features_df_mutual_5000 = pd.read_csv(\"./data/features_df_mutual_5000.csv\", index_col='ID_REF')\n",
    "features_df_chi2_5000 = pd.read_csv(\"./data/features_df_chi2_5000.csv\", index_col='ID_REF')\n",
    "features_df_fc_5000 = pd.read_csv(\"./data/features_df_fc_5000.csv\", index_col='ID_REF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a50566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorez rapidement les 3 DataFrames pour bien comprendre les données.\n",
    "features_df_mutual_5000.head()\n",
    "print(features_df_mutual_5000['leukemia_class'].value_counts())\n",
    "print(features_df_chi2_5000.head())\n",
    "print(features_df_fc_5000.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f82ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column names (features names / noms d'attributs)\n",
    "cols_mutual = list(features_df_mutual_5000.columns)\n",
    "cols_chi2 = list(features_df_chi2_5000.columns)\n",
    "cols_fc = list(features_df_fc_5000.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0b3e4",
   "metadata": {},
   "source": [
    "### Total features union\n",
    "\n",
    "Si l'on prend la totalité des variables choisies par nos trois méthodes, nous obtenons 7615 variables différentes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features union\n",
    "all_features_union = set(cols_mutual + cols_chi2 + cols_fc)\n",
    "print(len(all_features_union))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3759f7",
   "metadata": {},
   "source": [
    "### Total features intersection\n",
    "\n",
    "Si l'on choisi de prendre uniquement les variables sélectionnées par nos trois méthodes, nous obtenons 2458 variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60daecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features intersection\n",
    "all_features_intersect = set(cols_mutual).intersection(cols_chi2).intersection(cols_fc)\n",
    "print(len(all_features_intersect))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e7b4b",
   "metadata": {},
   "source": [
    "### Total features union of intersections\n",
    "\n",
    "Nous pouvons choisir les variables qui ont été retenues par au moins deux méthodes en prenant l'union des intersections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7556bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total features union of intersections\n",
    "\n",
    "# Intersection between the 5000 columns of mutual_information and the 5000 of chi2\n",
    "features_mutual_n_chi2 = set(cols_mutual).intersection(cols_chi2)\n",
    "l_mutual_chi2 = len(features_mutual_n_chi2)\n",
    "print(f\"Intersection between mutual and chi2: {l_mutual_chi2}\")\n",
    "\n",
    "# Same with mutual_information and f_classifier\n",
    "features_mutual_n_fc = set(cols_mutual).intersection(cols_fc)\n",
    "l_mutual_fc = len(features_mutual_n_fc)\n",
    "print(f\"Intersection between mutual and fc: {l_mutual_fc}\")\n",
    "\n",
    "# Same with f_classifier and chi2\n",
    "features_fc_n_chi2 = set(cols_fc).intersection(cols_chi2)\n",
    "l_fc_chi2 = len(features_fc_n_chi2)\n",
    "print(f\"Intersection between fc and chi2: {l_fc_chi2}\")\n",
    "\n",
    "# Intersection between the three (length)\n",
    "l_fc_chi2_mutual = len(set(cols_fc).intersection(cols_chi2).intersection(cols_mutual))\n",
    "print(f\"Intersection between mutual, fc and chi2: {l_fc_chi2_mutual}\")\n",
    "\n",
    "\n",
    "print(\"-------------------\")\n",
    "\n",
    "# Creating a set removes the duplicates (intersection between the three are present multiple times until now)\n",
    "all_features_union_of_intersect = list(set(list(features_mutual_n_chi2) + \n",
    "                                           list(features_mutual_n_fc) + \n",
    "                                           list(features_fc_n_chi2)))\n",
    "\n",
    "print(f\"Union of intersections {len(all_features_union_of_intersect)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f020e1",
   "metadata": {},
   "source": [
    "Voici un petit diagramme de Venn pour vous aider à visualiser les features en commun entre les différentes méthodes (calculs fait à la main à partir des intersections)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn3\n",
    " \n",
    "v=venn3(subsets = (472, 2024, 116, 186,1954,402,2458), set_labels = ('Mutual information', 'Chi2', 'f classifier'))\n",
    "#v.get_label_by_id('A').set_text('My Favourite group!')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1651c",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Décrivez le dataset MILE et son contenu. D'où vient-il et quel est son but ? Que représentent les données ? Donnez des informations sur les variables indépendantes, sur la variable dépendante, la tâche de machine learning à effectuer etc. \n",
    "  - **Le dataset MILE (Microarray Innovations in LEukemia) contient les expressions de gènes pour 2096 patients dont le génotype a été analysé. Les variables indépendantes sont les expressions de gênes (toutes les colonnes sauf la première et la dernière) et la variable dépendante est la dernière colonne `leukemia_class`, qui indique si le patient est en bonne santé ou si il est atteint de leucémie (18 classes différentes). La tâche de ML à effectuer est de trouver les gênes permettant le mieux de prédire la valeur de `leukemia_class`. Le but n'est pas seulement de prédire la bonne classe mais surtout de trouver quels sont les gênes ayant un impact dessus.**\n",
    "- Donnez une description des trois méthodes utilisées pour le premier filtre\n",
    "  - **Mutual Information : La sélection de caractéristique avec l'information mutuelle fonctionne en calculant la quantité d'information que chaque variable explicative partage avec la variable cible. En d'autres termes, l'information mutuelle permet de quantifier la dépendance entre deux variables.**\n",
    "  - **Chi-squared (Chi2) : Le critère chi-carré fonctionne en comparant le nombre d'occurences des valeurs des variables avec la variable cible pour déterminer si la variable explicative et la variable cible sont plus liées si elles étaient complètement indépendantes. Un chi-carré élevé indique une forte corrélation.**\n",
    "  - **f classifier : Le F-classifier se base sur une analyse de variance des différentes caractéristiques en comparant la variance intra-classe et la variance inter-classe.**\n",
    "- Pourquoi utiliser des méthodes simples commes celles-ci pour une première étape de filtre ?\n",
    "  - **Car cela permet d'élaguer les variables qui ne seront probablement pas importantes, avant d'avoir recours à des méthodes plus complexes et donc plus coûteuse.**\n",
    "- Nous choisissons de garder l'union des intersections des features (création du DF ci-dessous). D'après vous, pourquoi faire ce choix plutôt que de garder la totalité des features sélectionnées par les trois méthodes (union) ou les features en commun entre les trois méthodes (intersection) ?\n",
    "  - **Pour contrer le problème des biais inhérent à l'utilisation de modèle de Feature Selection.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08509d1c",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24606a36",
   "metadata": {},
   "source": [
    "On crée notre DataFrame *df_union_intersect* qui va être utilisé pour la suite du TP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0653ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column lists from each method\n",
    "mutual_columns = features_df_mutual_5000.columns.tolist()\n",
    "chi2_unique = [col for col in features_df_chi2_5000.columns if col not in mutual_columns]\n",
    "fc_unique   = [col for col in features_df_fc_5000.columns if col not in (mutual_columns + chi2_unique)]\n",
    "\n",
    "# Concatenate the selected columns to form the union DataFrame\n",
    "df_union = pd.concat([\n",
    "    features_df_mutual_5000[mutual_columns],\n",
    "    features_df_chi2_5000[chi2_unique],\n",
    "    features_df_fc_5000[fc_unique]\n",
    "], axis=1)\n",
    "\n",
    "# Retain only the features selected by at least two methods (union of intersections)\n",
    "df_union_intersect = df_union.loc[:, all_features_union_of_intersect]\n",
    "\n",
    "# Retain only the features selected by all three methods (intersection)\n",
    "df_intersect = df_union.loc[:, list(all_features_intersect)]\n",
    "\n",
    "# Move 'leukemia_class' to the last column\n",
    "leukemia_class = df_union_intersect.pop(\"leukemia_class\")\n",
    "df_union_intersect[\"leukemia_class\"] = leukemia_class\n",
    "\n",
    "df_union_intersect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e48cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1411063",
   "metadata": {},
   "source": [
    "## 2) Wrapper methods\n",
    "\n",
    "\n",
    "Nous allons maintenant utiliser deux *wrapper methods* afin de réduire notre sélection d'environ 5'000 attributs à environ 500 (ordre de grandeur). Pour cela nous allons utiliser la Recursive Features Elimination (RFE) de scikit-learn avec Random Forest et Support Vector Machine. \n",
    "\n",
    "(*Note: sans Cross Validation (rfecv) car très demandant en ressources*)\n",
    "\n",
    "\n",
    "- Répondez aux questions \n",
    "- RFE-RF: Exécutez le code donné et répondez aux questions\n",
    "- RFE-SVM: Complétez le code demandé et répondez aux questions\n",
    "- Sélectionnez les features que vous garderez pour la prochaine étape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a19235",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Questions:\n",
    "\n",
    "- Écrivez une courte description de ce que sont les méthodes \"wrapper\" pour la sélection d'attributs. Comment fonctionne RFE (implémentation de sklearn) \n",
    "- Pourquoi est-il possible de l'utiliser avec Random Forest et Support Vector Machine (SVM) ?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3609813",
   "metadata": {},
   "source": [
    "*Réponse: Un wrapper compare les différents ensemble de features en entraînant complètement le modèle pour chacun de ces sous-ensembles et en comparant les performances finales. Le sous-ensemble donnant les meilleurs performances (ou le plus \"rentable\" en fonction du nombre de features gardées) est considéré comme le meilleur.*\n",
    "\n",
    "*La RFE (Recursive Feature Elimination) commence en partant de l'ensemble initial de features et teste récursivement les sous-ensemble avec une feature en moins à chaque fois.*\n",
    "\n",
    "*On peut utiliser les algorithmes Random Forest et SVM car leurs fonctionnement est relativement \"transparent\" et permet de facilement extraire les coefficients associés à chaque feature pour déterminer lesquelles sont les plus importantes pour le modèle.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2f5a2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données \n",
    "\n",
    "X_uoi, y_uoi = df_union_intersect.drop(columns=\"leukemia_class\"), df_union_intersect[\"leukemia_class\"]\n",
    "\n",
    "X_i, y_i = df_intersect.drop(columns=\"leukemia_class\"), df_intersect[\"leukemia_class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ad0e7",
   "metadata": {},
   "source": [
    "### RFE-RF\n",
    "\n",
    "Exécuter le code donné ci-dessous. Complétez les commentaires (les # sans rien) dans le code afin d'expliquer ce qui est fait puis répondez aux questions.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> Temps d'exécution avec les paramètres actuels: RFE-RF (50 sec) / RFE-SVM (5 minutes avec LinearSVC, 30 secondes avec SVC)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#---------------\n",
    "\n",
    "# Création d'un modèle de sélection de feature récursif basé sur RandomForest\n",
    "selector = RFE(estimator=RandomForestClassifier(random_state=0, \n",
    "                                                n_estimators=25, \n",
    "                                                max_depth=10), \n",
    "               n_features_to_select=500, \n",
    "               step=0.02)\n",
    "\n",
    "# Entraînement du modèle (recherche des features)\n",
    "selector = selector.fit(X_uoi, y_uoi)\n",
    "\n",
    "# Récupération des colonnes importantes trouvées par le modèle\n",
    "features_names_RFERF = X_uoi.columns[selector.support_]\n",
    "\n",
    "#---------------\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "# without step: 1581 sec\n",
    "# with step: 49 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06338fc9",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "On cherche à retirer les variables qui sont les plus mauvais prédicteurs. Quelle influence cela a-t-il sur le choix des paramètres de notre RandomForestClassifier ? En d'autres termes: Que changeriez-vous si vous utilisiez Random Forest pour créer un modèle performant au lieu de l'utiliser pour éliminer les plus mauvaises features ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e5b2f5",
   "metadata": {},
   "source": [
    "*Réponse : En Feature Selection, le but est de trouver l'importance de chaque feature plutôt que d'avoir un modèle vraiment performant. On va donc privilégier un modèle plus simple. Dans notre cas, la Random Forest n'a que 25 estimateurs peu profonds alors qu'en pratique il en faudrait beaucoup plus et plus profonds pour avoir un modèle performant.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919885a4",
   "metadata": {},
   "source": [
    "---\n",
    "### RFE-SVM\n",
    "\n",
    "En vous basant sur le code de RFE-RF ci-dessus, écrivez le code pour une RFE avec cette fois-ci l'estimateur SVM. \n",
    "\n",
    "Utilisez les paramètres suivant:\n",
    "- Pour RFE: \n",
    "    - estimator = SVC\n",
    "    - N_features: 500\n",
    "    - step=0.05\n",
    "\n",
    "\n",
    "- Pour SVC\n",
    "    - Kernel = 'linear'\n",
    "    - C=1\n",
    "    - max_iter=1000\n",
    "\n",
    "Gardez les noms des 500 features choisies dans une variable nommée *features_names_RFESVM*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bee935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Création d'un modèle de sélection de feature récursif basé sur SVM\n",
    "selector = RFE(estimator=SVC(kernel='linear', C=1, max_iter=1000),\n",
    "               n_features_to_select=500,\n",
    "               step=0.05)\n",
    "\n",
    "# Entraînement du modèle (recherche des features)\n",
    "selector = selector.fit(X_uoi, y_uoi)\n",
    "\n",
    "# Récupération des colonnes importantes trouvées par le modèle\n",
    "features_names_RFESVM = X_uoi.columns[selector.support_]\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedefbd9",
   "metadata": {},
   "source": [
    "### Features retenues par les deux méthodes\n",
    "\n",
    "Créez une liste nommée \"**features_names_wrapper**\" avec l'**union** des features retenues. Vous devriez obtenir environ 8-900 features en tout. Affichez vos résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a817f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union des features de features_names_RFESVM et features_names_RFERF\n",
    "\n",
    "features_names_wrapper = set(features_names_RFERF).union(set(features_names_RFESVM))\n",
    "print(len(features_names_RFERF))\n",
    "print(len(features_names_RFESVM))\n",
    "print(len(features_names_wrapper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349168d",
   "metadata": {},
   "source": [
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2917d68",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "- Pourquoi garder les ~8-900 features issues de l'union et pas uniquement les ~100 de l'intersection ?\n",
    "  - *Réponse :* Chaque algorithme est plus ou mois biaisé. On ne voudrait pas supprimer une feature juste parce que un des modèles ne l'a pas trouvée pertinentes (modèle biaisé). Pour résoudre ce problème, on ne rejette que les features qui sont rejetés par les deux modèles.\n",
    "- Dans un contexte plus réél avec du temps et des ressources en quantité, comment auriez-vous amélioré l'utilisation de RFE pour faire une sélection encore plus pértinente de variables ?\n",
    "  - *Réponse :* Il faudrait chercher les meilleurs hyperparamètres pour les estimateurs afin d'avoir des résultats robustes. De plus, on pourrait utiliser plusieurs autres méthodes de FS afin d'augmenter la crédibilité de la sélection finale.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d844a3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3feef",
   "metadata": {},
   "source": [
    "*Réponse:* Voir ci-dessus ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af64335",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Embedded\n",
    "\n",
    "\n",
    "### Préparation des données\n",
    "\n",
    "Exécutez le code ci-dessous.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données: reprendre df_union_intersect et ne prendre que les colonnes qui sont dans features_names_wrapper\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df_union_intersect.loc[:, df_union_intersect.columns.intersection(features_names_wrapper)]\n",
    "y = df_union_intersect[\"leukemia_class\"].to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.2) # 80% training and 20% test\n",
    "\n",
    "print(\"-----------\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {len(y_train)}\")\n",
    "print(f\"y_test shape: {len(y_test)}\")\n",
    "print(\"-----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c87666",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "En vous inspirant de l'utilisation faite de Random Forest pour la sélection d'attribut, utilisez [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) pour créer un classificateur avec les données générées ci-dessus. Vous pouvez lire [cet article de DataCamp](https://www.datacamp.com/tutorial/random-forests-classifier-python) si vous voulez vous raffraichir sur Random Forest. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez brièvement avec les paramètres possibles améliorer l'accuracy. \n",
    "\n",
    "Note: \n",
    "- Le paramètre n_jobs=-1 vous permet de paralléliser le travail sur tous vos coeurs. Avec 8 coeurs le travail prend environ 2 minutes. \n",
    "- Nous voulons tester l'importance de toutes les features, on va donc toutes les tester: utilisez le paramètre \"**max_features=len(X.columns)**\"\n",
    "- Vous pouvez aussi prendre un grand nombre d'estimateurs e.g. \"**n_estimators=400**\"\n",
    "- Suivez le code donné en commentaires\n",
    "- Une fois le modèle entrainé, les \"feature importances\" sont accessibles dans *rf_clf.feature_importances_*\n",
    "- Vous pouvez générer une pandas.Series en donnant les noms de features comme indexes et utiliser la fonction sort_values(ascending=False) pour trier les valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f24df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    random_state=0, \n",
    "    n_estimators=400, \n",
    "    max_features=len(X.columns),\n",
    "    n_jobs=-1)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "feature_imp_RF = pd.Series(rf_clf.feature_importances_, index=X.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_imp_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acb629f",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- L'algorithme Random Forest va construire un ensemble d'arbres de décisions de petite taille contrairement au Decision Tree Classifier qui va construire un arbre de grande taille. Décrivez les paramètres *n_estimators*, *max_depth* et *min_samples_leaf* de RandomForestClassifier. \n",
    "  - *Réponse :* \n",
    "    - n_estimators -> nombre de weak learners de la forêt (nombre d'arbres dans la forêt)\n",
    "    - max_depth -> profondeur maximale de chaque arbre\n",
    "    - min_samples_leaf -> nombre minimum d'échantillons requis pour être une feuille\n",
    "\n",
    "- Décrivez les résultats obtenus. Que représente la \"feature importance\" ?\n",
    "  - *Réponse :* Nous obtenons une accuracy de 0.873. La feature importance indique à quel point une feature est \"décisive\" dans les arbres (décisif = qui réduit beaucoup l'impureté)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb51286",
   "metadata": {},
   "source": [
    "### Support Vector Machine - SVC\n",
    "\n",
    "Comme pour Random Forest, nous voulons ici créer un modèle qui nous permet d'avoir l'importance que chaque feature. Nous allons de nouveau utiliser [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Pour pouvoir obtenir l'importance des features, nous devons utiliser un kernel lineaire. Inspirez-vous du code en commentaires ci-dessous pour créer un classificateur. \n",
    "\n",
    "Une fois le classificateur créé, déterminez son accuracy puis générez la liste de l'importance de chaque feature. Jouez avec les paramètres possibles pour trouver une $accuracy > 93\\%$. \n",
    "\n",
    "Note: \n",
    " \n",
    "- Les importances d'attributs peuvent être obtenus avec *abs(svc_clf.coef_[0])*\n",
    "- Les paramètres par défaut donnent déja de bons résultats\n",
    "- Suppor Vector Machine: SVC = Classificateur, SVR = Régression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ec54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code pour tester un grand nombre de combinaisons de paramètres :\n",
    "\"\"\"\n",
    "for c in range(1, 10):\n",
    "    for gamma in ['scale', 'auto']:\n",
    "        for class_weight in [None, 'balanced']:\n",
    "            for dfs in ['ovr', 'ovo']:\n",
    "                for bt in [True, False]:\n",
    "                    svc_clf = SVC(\n",
    "                        kernel='linear',\n",
    "                        C=float(c),\n",
    "                        gamma=gamma,\n",
    "                        tol=0.001,\n",
    "                        class_weight=class_weight,\n",
    "                        decision_function_shape=dfs,\n",
    "                        break_ties=bt if dfs != 'ovo' else False\n",
    "                        )\n",
    "                    svc_clf.fit(X_train, y_train)\n",
    "\n",
    "                    y_pred = svc_clf.predict(X_test)\n",
    "\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "                    #feature_imp_SVC = pd.Series(abs(svc_clf.coef_[0]), index=X_train.columns).sort_values(ascending=False)\n",
    "                    #print(feature_imp_SVC)\n",
    "\"\"\"\n",
    "\n",
    "# Pas obtenu de meilleurs résultats avec la recherche donc nous gardons les paramètres par défaut\n",
    "svc_clf = SVC(\n",
    "    kernel='linear',\n",
    "    )\n",
    "svc_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "feature_imp_SVC = pd.Series(abs(svc_clf.coef_[0]), index=X_train.columns).sort_values(ascending=False)\n",
    "print(feature_imp_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09bf383",
   "metadata": {},
   "source": [
    "*Résultats :* Même avec une recherche assez extrême, nous n'avons pas trouvé de combinaisons de paramètres donnant une accuracy supérieur à 0.93. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc38ba",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Final feature selection\n",
    "\n",
    "Nous avons maintenant nos deux *pandas.Series* contenant les features et leurs importances obtenues avec Random Forest et SVM que nous mettons ci-dessous dans un joli DataFrame appelé features_RF_SVC. Après avoir vérifié que tout est dans le bon sens, ce qui normalement ne devrait pas poser problème, faites ceci:\n",
    "\n",
    "- Pour choisir les features les plus importantes, créez une troisième colonne contenant la **somme des deux autres** puis ordrez par ordre décroissant.\n",
    "\n",
    "- Sélectionnez en suite les N_first (210) features les plus importantes et récupérez la liste des indexes (df.index). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crée un DataFrame contenant les importances des features selon chaque méthode\n",
    "\n",
    "features_RF_SVC = pd.DataFrame(columns = ['Features_imp_SVC', 'Features_imp_RF'])\n",
    "features_RF_SVC['Features_imp_SVC'] = feature_imp_SVC\n",
    "features_RF_SVC['Features_imp_RF'] = feature_imp_RF\n",
    "\n",
    "# Vérifiez que les données ont bien été introduites dans le DataFrame selon le bon indexe\n",
    "\n",
    "feature_imp_RF.loc[\"227998_at\"]\n",
    "feature_imp_SVC.loc[\"227998_at\"]\n",
    "features_RF_SVC.loc[\"227998_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_RF_SVC[\"sum_of_importances\"] = features_RF_SVC['Features_imp_SVC'] + features_RF_SVC['Features_imp_RF']\n",
    "\n",
    "features_RF_SVC.sort_values(by='sum_of_importances', ascending=False)\n",
    "\n",
    "N_first = 210\n",
    "\n",
    "n_first_idx = list(features_RF_SVC.iloc[:N_first,:].index)\n",
    "\n",
    "print(f\"Total selected features: {len(n_first_idx)}\")\n",
    "\n",
    "features_RF_SVC.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba4323",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "Avant d'évaluer la sélection, discutez de la méthode choisies pour garder les 210 premières variables. Quels sont les avantages ou les inconvénients d'utiliser la somme  des \"feature importance\" ? Utiliser le ranking (1er, 2ème, etc) représente-t-il une alternative envisageable ? Pourquoi ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaba7dc",
   "metadata": {},
   "source": [
    "*Réponse:* Le problème principal de cette méthode réside dans le fait que l'importance des features n'est pas normalisé avant d'être sommé. Du coup, si un estimateur donne plus d'importance à toutes les features en général alors cet estimateur va avoir davantage de poids dans la sélection de features finales, ce qui n'est pas désirable.\n",
    "\n",
    "Utiliser le ranking résoud en partie le problème car cela va normaliser implicitement l'importance des features. Ce n'est peut-être pas la meilleure solution mais c'est probablement bien meilleur que la somme des importances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcae6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7e355",
   "metadata": {},
   "source": [
    "Nous construisons en suite nos splits de données pour pouvoir entrainer nos models avec les 210 variables les plus pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca24a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des données avec les 210 premières features sélectionnées\n",
    "\n",
    "X_n_first = df_union_intersect.loc[:, n_first_idx]\n",
    "y_n_first = df_union_intersect[\"leukemia_class\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f21ff",
   "metadata": {},
   "source": [
    "---\n",
    "Ci-dessous vous trouverez une fonction pour évaluer vos features sélectionnez. \n",
    "\n",
    "### Question : \n",
    "\n",
    "- Décrivez rapidement ce que fait la fonction \n",
    "- Pourquoi utiliser trois classificateurs différents?\n",
    "- Comment rendre la méthode d'évaluation plus robuste ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d6d2b",
   "metadata": {},
   "source": [
    "*Réponse* :\n",
    "\n",
    "La fonction utilise 3 modèles différents pour évaluer la sélection de features. Elle va simplement entraîner ces modèles avec les données de tests et l'ensemble de features à tester et afficher la moyennes des accuracies obtenues.\n",
    "\n",
    "Utiliser 3 classificateurs différents permet d'obtenir un résultat plus crédible car cela va combler les biais entre chaque modèle. Si un des modèle obtient un très mauvais résultat, cela va fortement impacter la moyenne.\n",
    "\n",
    "Pour rendre cette méthode d'évaluation plus robuste on pourrait utiliser encore plus des classificateurs différents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1232d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_feature_selection(X, y, show=True):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)    \n",
    "    common_labels = np.unique(y_test)\n",
    "    \n",
    "    models = [\n",
    "        LogisticRegression(max_iter=1000),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier()\n",
    "    ]\n",
    "    \n",
    "    accuracies = []\n",
    "    combined_cm = None\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))        \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=common_labels)\n",
    "        \n",
    "        # Sum the confusion matrices element-wise.\n",
    "        if combined_cm is None:\n",
    "            combined_cm = cm\n",
    "        else:\n",
    "            combined_cm += cm\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    \n",
    "    if show:\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(combined_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=common_labels, yticklabels=common_labels)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Combined Confusion Matrix (Sum of all models)\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"\\nMean Accuracy across models: {mean_accuracy:.4f}, with standard deviation: {np.std(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad1055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilisez la fonction pour évaluer la performance de votre sélection de features n_first_idx\n",
    "evaluate_feature_selection(X_n_first, y_n_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d22467",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ensemble Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9aad96",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné de différentes manières les résultats obtenus par ces méthodes, approchant ainsi ce qu'on appelle l'ensemble feature sélection, c'est-à-dire l'utilisation et la combinaison de plusieurs méthodes de FS, à l'image de l'ensemble learning.\n",
    "\n",
    "Nous vous proposons désormais d'utiliser un paquet Python en cours de développement qui automatise les différentes étapes de l'ensemble feature sélection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5978bb42",
   "metadata": {},
   "source": [
    "Nous avons exploré trois types de méthodes de sélection de features : filter, wrapper et embedded. Nous avons combiné leurs résultats de différentes manières, approchant ainsi l’ensemble feature sélection, qui consiste à utiliser et combiner plusieurs méthodes de FS, à l’image de l’ensemble learning.\n",
    "\n",
    "Pour automatiser ces différentes étapes, nous vous proposons d’utiliser un paquet Python en cours de développement.\n",
    "\n",
    "Code disponible sur GitHub : [ensemblefs](https://github.com/arthurbabey/ensemblefs/)  \n",
    "Documentation : [Accéder à la doc](https://arthurbabey.github.io/ensemblefs/)  \n",
    "\n",
    "\n",
    "Installation :\n",
    "```bash\n",
    "pip install git+https://github.com/arthurbabey/ensemblefs.git\n",
    "```\n",
    "\n",
    "Le projet est en cours de développement, si vous observez des bugs ou des améliorations possibles, n’hésitez pas à les signaler !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/arthurbabey/ensemblefs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe35bb",
   "metadata": {},
   "source": [
    "Voici une rapide présentation de la méthodologie mise en place lors de la sélection avec ensemble dans ce paquet :\n",
    "\n",
    "1. Utiliser plusieurs sélecteurs pour obtenir des listes de features.  \n",
    "2. Combiner ces listes via une stratégie de fusion (par défaut, l'union des intersections).  \n",
    "3. Répéter la sélection N fois pour créer divers groupes, chaque groupe étant la combinaison de plusieurs listes de features.  \n",
    "4. Calculer des métriques de performance et de stabilité.  \n",
    "5. Employer une méthode de type Pareto pour optimiser la sélection en fonction de la performance et de la stabilité.  \n",
    "6. Comparer les groupes, identifier les meilleurs, et retourner leur liste de features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cba1ec",
   "metadata": {},
   "source": [
    "Comme le processus d'ensemble feature sélection peut être couteux en temps nous allons l'utiliser pour la dernière étape : passer des 879 features sélectionnées après la méthode embedded jusqu'à une liste final de 210 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère les données après l'étape de sélection des features embedded \n",
    "RF_SVC_index = list(features_RF_SVC.index)\n",
    "\n",
    "df_efs = df_union_intersect.loc[:, RF_SVC_index+[\"leukemia_class\"]]\n",
    "df_efs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4741336",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer une instance FeatureSelectionPipeline en définissant chaque attributs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --force-reinstall -v \"scikit-learn==1.6.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemblefs import FeatureSelectionPipeline\n",
    "#from sklearn.utils._tags import Tags\n",
    "\n",
    "data = df_efs.rename(columns={\"leukemia_class\": \"target\"}) # créer une colonne target\n",
    "data[\"target\"] = data[\"target\"].astype(\"category\").cat.codes # convertir la colonne target en catégorique\n",
    "\n",
    "fs_methods = [\"random_forest_selector\", \"svm_selector\", \"lasso_selector\", \"xgboost_selector\"]\n",
    "merging_strategy = \"union_of_intersections_merger\"\n",
    "num_repeats = 5 \n",
    "task = \"classification\" \n",
    "num_features_to_select = 210\n",
    "metrics = [\"logloss\", \"f1_score\"]\n",
    "min_group_size = 2\n",
    "fill = True\n",
    "random_state = 123\n",
    "n_jobs = 5\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data, # pandas dataset avec la colonne target\n",
    "    fs_methods=fs_methods, # list des méthodes de sélection de features, soit en utlisant le nom de la méthode soit en créant un objet de la classe de la méthode de sélection\n",
    "    merging_strategy=merging_strategy, # stratégie de fusion des features sélectionnées\n",
    "    num_repeats=num_repeats, # nombre de répétitions pour chaque méthode de sélection de features\n",
    "    task=task, # classification ou régression\n",
    "    num_features_to_select=num_features_to_select, # nombre de features à sélectionner\n",
    "    metrics=metrics, # liste des métrique de performance à utiliser pour évaluer les features sélectionnées (minimum 1)\n",
    "    min_group_size=min_group_size, # taille minimale du groupe de features sélectionnées\n",
    "    fill=fill, # combler les features sélectionnées jusqu'à num_features_to_select si la stratégie de fusion ne les atteint pas\n",
    "    random_state=random_state, # random seed\n",
    "    n_jobs=n_jobs # nombre de coeurs à utiliser pour le calcul parallèle\n",
    ")\n",
    "\n",
    "selected_features, _, _ = pipeline.run() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af064bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_efs[list(selected_features)], df_efs[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d182e490",
   "metadata": {},
   "source": [
    "---\n",
    "Maintenant, essayez de modifier les paramètres pour voir si vous pouvez améliorer les résultats. Vous pouvez ajuster ceux proposés dans la prochaine cellule.\n",
    "\n",
    "Expérimentez avec différents réglages et expliquez vos choix. Inutile de chercher exhaustivement les meilleurs paramètres, car la méthode est coûteuse en temps de calcul.\n",
    "\n",
    "Vous pouvez trouver dans le code ou dans la documentations les différents feature selectors possible ainsi que les metrics possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0170326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif, f_classif, SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "fs_methods = [\n",
    "    \"mutual_info_selector\",       # Capturer des relations non linéaires\n",
    "    \"random_forest_selector\",     # Importance des features via RF\n",
    "    \"lasso_selector\",             # Réduction des features avec L1\n",
    "    \"xgboost_selector\",           # Importance des features via XGBoost\n",
    "]\n",
    "\n",
    "\n",
    "metrics = [\"f1_score\", \"accuracy\"]\n",
    "min_group_size = 4\n",
    "\n",
    "pipeline = FeatureSelectionPipeline(\n",
    "    data=data,\n",
    "    fs_methods=fs_methods,\n",
    "    merging_strategy=merging_strategy,\n",
    "    num_repeats=num_repeats,\n",
    "    task=task,\n",
    "    num_features_to_select=num_features_to_select,\n",
    "    metrics=metrics,\n",
    "    min_group_size=min_group_size,\n",
    "    fill=fill,\n",
    "    random_state=random_state,\n",
    "    n_jobs=n_jobs\n",
    ")\n",
    "\n",
    "selected_features_2, _ , _ = pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f734d",
   "metadata": {},
   "source": [
    "*Justification:*\n",
    "\n",
    "Nous avons ajouté `mutual_info_selector` qui permet de prendre en compte les dépendances entre variables et le sélecteur LASSO fait une réduction de dimensionnalité donc c'est également bénéfique pour trouver les features importantes.\n",
    "\n",
    "Concernant les métriques, nous avons utilisé l'`accuracy` au lieu de la `logloss`\n",
    "\n",
    "Pour `min_group_size` nous avons essayé avec 4 au lieu de 2 méthodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212e52b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_union[list(selected_features_2)], df_union[\"leukemia_class\"]\n",
    "\n",
    "evaluate_feature_selection(X, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00832c6c",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "- Pourquoi est-il important lors de feature sélection par ensemble d'utiliser des sélecteurs différents ? \n",
    "- Qu'est-ce que le paramètre min_group_size et comment influence-t-il la sélection des features ? \n",
    "- Comparez les résultats obtenus lors de l'évaluation de selected_features et selected_features_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731e30ec",
   "metadata": {},
   "source": [
    "*Réponse:* \n",
    "Il est essentiel d'utiliser des sélecteurs différents pour s'assurer que l'union des groupes de features sélectionnés soit la plus robuste possible. Si on utilisait toujours le même sélecteur, les groupes seraient probablement identiques car la sélection serait biaisée par les propriétés de l'unique selecteur utilisé.\n",
    "\n",
    "Selon la documentation (https://github.com/arthurbabey/ensemblefs/blob/main/ensemblefs/feature_selection_pipeline.py), le paramètre `min_group_size` permet de définir le nombre minimal de méthodes de FS utilisées pour la création de chaque groupe.\n",
    "\n",
    "Comparaison des résultats obtenus : On obtient une accuracy très légèrement meilleure (0.8444 vs 0.8437) avec un écart type un peu plus petit également (0.0496 vs 0.0506). On pourrait en conclure que ce sont des meilleurs paramètres car on obtient une meilleure accuracy avec un écart type plus petit donc une sélection plus stable mais la différence est tellement petite que c'est débatable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f0925",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a4ee8f",
   "metadata": {},
   "source": [
    "## Visualisation et analyse\n",
    "\n",
    "- Analyser une des matrices de confusion calculée ci-dessus. Quelle erreure de prédiction peut être plus grave que d'autres ?\n",
    "- On vous donne ci-dessous la liste des 210 variables les plus pertinentes obtenues lors d'un projet d'une durée de 3 ans avec beaucoup plus de moyens (temps, ressources, experts médicaux, etc). Comparez cette liste avec les listes obtenues dans ce TP (les 210 obtenus après toute les étapes et les 210 obtenus avec l'ensemble feature selection) et discutez rapidement les résultats. \n",
    "\n",
    "\n",
    "*Réponse :*\n",
    "\n",
    "Étant donné que l'on est dans un domaine médical, les faux-négatifs sont plus dangereux que les faux-positifs. En d'autres termes, on préfère avoir un modèle un peu trop sensible qui aura tendance à prédire tous les cas de leucémie, même si cela revient à beaucoup de fausses alertes (=rappel élevé). Cela dit, un trop grand nombre de fausses alertes peut également être néfaste car si il y en a trop, cela risque de \"diluer\" les vrais-positifs dans un trop grand nombre de faux-positifs (le corps médical risque d'être surchargé si il y a beaucoup de personnes à tester suit à une alerte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199cc3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des 210 variables\n",
    "# Comparez avec vos données obtenues\n",
    "import pickle\n",
    "\n",
    "# read pickle \n",
    "with open(\"./data/list_210_features.pickle\", \"rb\") as fp:   #Pickling\n",
    "    experts_list = pickle.load(fp)\n",
    "    \n",
    "print(experts_list)\n",
    "print(selected_features_2)\n",
    "\n",
    "# intersection entre les deux, pour savoir combien des \"bonnes\" features on a réussi à trouver dans ce tp\n",
    "common_features = set(experts_list).intersection(selected_features_2)\n",
    "print(len(common_features))\n",
    "print(len(experts_list))\n",
    "print(len(selected_features_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f9eac",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n",
    "Sur les 210 features trouvées par des experts, 60 sont communes avec celles que nous avons trouvées (~28%), c'est un résultat un peu décevant mais nous n'avons pas eu accès aux mêmes ressources que ces experts, il est donc difficile de savoir si notre résultat est bien ou non par rapport au mieux qu'il était possible de faire avec ce qu'on avait."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e143fa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60215329",
   "metadata": {},
   "source": [
    "Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labos-xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
